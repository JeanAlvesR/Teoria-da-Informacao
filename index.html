<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Explorador Interativo da Teoria da Informa√ß√£o</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; background-color: #FDF8F0; color: #334155; }
        .nav-link { transition: all 0.2s ease-in-out; }
        .nav-link.active { background-color: #F97316; color: #FFFFFF; font-weight: 500; }
        .content-section { display: none; }
        .content-section.active { display: block; animation: fadeIn 0.5s ease-in-out; }
        @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }
        .chart-container { position: relative; width: 100%; max-width: 600px; margin-left: auto; margin-right: auto; height: 300px; max-height: 40vh; }
        .venn-diagram { position: relative; width: 350px; height: 200px; margin: 2rem auto; }
        .venn-circle { position: absolute; border-radius: 50%; opacity: 0.5; transition: all 0.5s ease-in-out; }
        .venn-label { position: absolute; font-size: 0.8rem; font-weight: bold; color: #fff; text-shadow: 1px 1px 2px rgba(0,0,0,0.5); transition: all 0.5s ease-in-out; text-align: center; }
        .info-box { background-color: #FFFBEB; border-left: 4px solid #FBBF24; padding: 1rem; margin-top: 1rem; border-radius: 0.5rem; }
        .info-box-title { font-weight: 700; color: #D97706; }
    </style>
</head>
<body class="flex flex-col md:flex-row min-h-screen">

    <aside class="w-full md:w-72 bg-slate-100 border-b md:border-r border-slate-200 flex-shrink-0">
        <div class="p-6">
            <h1 class="text-xl font-bold text-slate-800">Teoria da Informa√ß√£o</h1>
            <p class="text-sm text-slate-500 mt-1">Um Guia Interativo (v2)</p>
        </div>
        <nav class="p-4">
            <ul class="space-y-1">
                <li><a href="#intro" class="nav-link block p-3 rounded-lg text-slate-700 hover:bg-slate-200">Introdu√ß√£o</a></li>
                <li><a href="#whatisinfo" class="nav-link block p-3 rounded-lg text-slate-700 hover:bg-slate-200">O Que √© Informa√ß√£o?</a></li>
                <li><a href="#entropy" class="nav-link block p-3 rounded-lg text-slate-700 hover:bg-slate-200">Entropia de Shannon</a></li>
                <li><a href="#compression" class="nav-link block p-3 rounded-lg text-slate-700 hover:bg-slate-200">Compress√£o: O Limite</a></li>
                <li><a href="#joint" class="nav-link block p-3 rounded-lg text-slate-700 hover:bg-slate-200">Entropia Conjunta e Condicional</a></li>
                <li><a href="#mutual" class="nav-link block p-3 rounded-lg text-slate-700 hover:bg-slate-200">Informa√ß√£o M√∫tua</a></li>
                <li><a href="#kl" class="nav-link block p-3 rounded-lg text-slate-700 hover:bg-slate-200">Entropia Cruzada &amp; KL</a></li>
            </ul>
        </nav>
    </aside>

    <main class="flex-1 p-4 md:p-10 overflow-y-auto">

        <section id="intro" class="content-section">
            <h2 class="text-3xl font-bold text-slate-800">O que √© Informa√ß√£o? A Revolu√ß√£o de Shannon</h2>
            <p class="mt-4 text-lg text-slate-600 leading-relaxed">
                Em 1948, Claude Shannon mudou o mundo. Ele prop√¥s uma teoria matem√°tica da comunica√ß√£o que, crucialmente, ignorava o *significado* das mensagens. Para Shannon, a informa√ß√£o n√£o era sobre sem√¢ntica, mas sobre **redu√ß√£o de incerteza**. Uma mensagem carrega mais informa√ß√£o quanto mais "surpreendente" ela for. Uma previs√£o de neve no Saara √© muito mais informativa do que uma previs√£o de sol. Esta aplica√ß√£o ir√° explorar essa ideia fundamental e suas consequ√™ncias profundas, desde a compress√£o de arquivos que usamos todos os dias at√© os fundamentos da aprendizagem de m√°quina.
            </p>
             <div class="mt-8 p-6 bg-white rounded-xl shadow-md border border-slate-200">
                <h3 class="font-bold text-lg text-slate-700">O Problema Fundamental da Comunica√ß√£o</h3>
                <p class="mt-2 text-slate-600">"O problema fundamental da comunica√ß√£o √© o de reproduzir em um ponto, exata ou aproximadamente, uma mensagem selecionada em outro ponto." - Claude Shannon</p>
                <p class="mt-4 text-slate-600">A genialidade de Shannon foi focar nos aspectos estat√≠sticos da fonte da mensagem, n√£o no seu conte√∫do. Isso permitiu a cria√ß√£o de uma teoria universal que serve de base para toda a era digital.</p>
            </div>
        </section>

        <section id="whatisinfo" class="content-section">
            <h2 class="text-3xl font-bold text-slate-800">O Que √© Informa√ß√£o?</h2>
            <p class="mt-4 text-lg text-slate-600 leading-relaxed">
                Para Shannon, a informa√ß√£o n√£o √© sobre o que uma mensagem *significa*, mas sobre a probabilidade de ela ser escolhida de um conjunto de possibilidades. Informa√ß√£o √© uma medida da **redu√ß√£o da incerteza**.
            </p>
            <div class="info-box">
                <p class="info-box-title">Analogia: O Carteiro Eficiente</p>
                <p class="mt-2 text-slate-600">Um carteiro n√£o precisa ler ou entender o conte√∫do das cartas para entreg√°-las corretamente. Ele se concentra no envelope e no endere√ßo. A teoria da informa√ß√£o foca na "embalagem" e no "transporte" da mensagem (os s√≠mbolos e o canal), n√£o no seu conte√∫do.</p>
            </div>
            <div class="mt-6 p-6 bg-white rounded-xl shadow-md border border-slate-200">
                <h3 class="font-bold text-lg text-slate-700">A Medida Logar√≠tmica e o Bit</h3>
                <p class="mt-2 text-slate-600">Shannon usou uma fun√ß√£o logar√≠tmica para medir a informa√ß√£o. Isso tem uma propriedade crucial: a informa√ß√£o de eventos independentes se soma. A unidade dessa medida, usando logaritmo de base 2, √© o **bit**. Um bit √© a quantidade de informa√ß√£o necess√°ria para resolver a incerteza entre duas alternativas igualmente prov√°veis.</p>
                <div class="flex items-center justify-center space-x-8 mt-6 text-center">
                    <div>
                        <div id="coin" class="w-24 h-24 rounded-full flex items-center justify-center text-4xl bg-slate-200 shadow-inner cursor-pointer select-none">?</div>
                        <p class="mt-2 font-semibold text-slate-800">Cara ou Coroa?</p>
                    </div>
                    <div>
                        <p class="text-slate-600">Informa√ß√£o Obtida:</p>
                        <p id="bit-info" class="text-3xl font-bold text-orange-500">0 bits</p>
                    </div>
                </div>
                <button id="flip-coin-btn" class="mt-6 w-full bg-blue-500 hover:bg-blue-600 text-white font-bold py-2 px-4 rounded-lg">Lan√ßar Moeda</button>
            </div>
        </section>

        <section id="entropy" class="content-section">
            <h2 class="text-3xl font-bold text-slate-800">Entropia (H): Medindo a Surpresa M√©dia</h2>
            <p class="mt-4 text-lg text-slate-600 leading-relaxed">
                A entropia, $H(X)$, √© a medida da incerteza ou "surpresa m√©dia" de uma fonte de informa√ß√£o. Fontes com resultados previs√≠veis (uma moeda viciada) t√™m baixa entropia, enquanto fontes com resultados imprevis√≠veis (um dado honesto) t√™m alta entropia. A f√≥rmula √© $H(X) = - \sum p(x) \log_2 p(x)$.
            </p>
             <div class="info-box">
                <p class="info-box-title">Analogia: A Caixa de Brinquedos</p>
                <p class="mt-2 text-slate-600">Uma caixa com brinquedos todos misturados e desorganizados tem alta entropia (alta incerteza sobre qual brinquedo voc√™ vai pegar). Uma caixa com brinquedos organizados em compartimentos tem baixa entropia.</p>
            </div>
            <div class="mt-6 p-6 bg-white rounded-xl shadow-md border border-slate-200">
                 <h3 class="font-bold text-lg text-slate-700">Laborat√≥rio de Entropia: O Dado Viciado</h3>
                 <p class="text-slate-600 mb-4">Ajuste as probabilidades de cada face de um dado e veja como a entropia do sistema muda. A entropia √© m√°xima quando todos os resultados s√£o igualmente prov√°veis.</p>
                 <div class="flex flex-col md:flex-row gap-8 items-start">
                    <div class="w-full md:w-1/2">
                        <div id="dice-controls"></div>
                    </div>
                    <div class="w-full md:w-1/2">
                        <div class="text-center">
                            <p class="text-slate-600">Entropia Total (H(X)):</p>
                            <p id="entropy-value" class="text-4xl font-bold text-orange-500">2.585 bits</p>
                            <p class="text-xs text-slate-500">(M√°xima para 6 resultados)</p>
                        </div>
                        <div class="chart-container mt-4">
                            <canvas id="entropyChart"></canvas>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        
        <section id="compression" class="content-section">
            <h2 class="text-3xl font-bold text-slate-800">Compress√£o: O Limite de Shannon</h2>
            <p class="mt-4 text-lg text-slate-600 leading-relaxed">
                O **Teorema da Codifica√ß√£o de Fonte** de Shannon afirma que √© imposs√≠vel comprimir dados sem perdas para uma taxa m√©dia de bits por s√≠mbolo menor que a entropia da fonte. A entropia define o limite te√≥rico da compress√£o. Algoritmos como a **Codifica√ß√£o de Huffman** se aproximam desse limite, dando c√≥digos mais curtos para s√≠mbolos mais frequentes.
            </p>
            <div class="mt-8 p-6 bg-white rounded-xl shadow-md border border-slate-200">
                <h3 class="font-bold text-lg text-slate-700">Construindo uma √Årvore de Huffman</h3>
                <p class="text-slate-600 mb-4">A partir das frequ√™ncias de caracteres, o algoritmo constr√≥i uma √°rvore combinando iterativamente os dois n√≥s de menor frequ√™ncia. Vamos construir uma para o texto "A_DEAD_DAD_CEDED_A_BEAD".</p>
                <div class="flex justify-center mb-4">
                     <button id="huffman-step-btn" class="bg-blue-500 hover:bg-blue-600 text-white font-bold py-2 px-4 rounded-lg">Pr√≥ximo Passo</button>
                     <button id="huffman-reset-btn" class="ml-4 bg-slate-500 hover:bg-slate-600 text-white font-bold py-2 px-4 rounded-lg">Reiniciar</button>
                </div>
                <div id="huffman-visualization" class="p-4 bg-slate-50 rounded-lg min-h-[200px] border">
                    <p id="huffman-status" class="text-center text-slate-500">Clique em "Pr√≥ximo Passo" para come√ßar.</p>
                </div>
                <div id="huffman-results" class="mt-4 hidden">
                    <h4 class="font-bold text-slate-700">Resultados da Codifica√ß√£o:</h4>
                    <div class="overflow-x-auto">
                        <table class="min-w-full divide-y divide-gray-200 mt-2">
                            <thead class="bg-gray-50"><tr><th class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Caractere</th><th class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Frequ√™ncia</th><th class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">C√≥digo Huffman</th><th class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Comprimento</th></tr></thead>
                            <tbody id="huffman-table-body" class="bg-white divide-y divide-gray-200"></tbody>
                        </table>
                    </div>
                    <div id="huffman-summary" class="mt-4 font-semibold text-slate-700"></div>
                </div>
            </div>
        </section>

        <section id="joint" class="content-section">
            <h2 class="text-3xl font-bold text-slate-800">Entropia Conjunta e Condicional</h2>
            <p class="mt-4 text-lg text-slate-600 leading-relaxed">
                Para entender a rela√ß√£o entre m√∫ltiplas vari√°veis, como Clima (X) e Tr√¢nsito (Y), usamos conceitos mais avan√ßados de entropia.
            </p>
            <div class="mt-6 grid grid-cols-1 md:grid-cols-2 gap-6">
                <div class="p-6 bg-white rounded-xl shadow-md border border-slate-200">
                    <h3 class="font-bold text-lg text-slate-700">Entropia Conjunta H(X, Y)</h3>
                    <p class="mt-2 text-slate-600">Mede a incerteza total de duas vari√°veis ocorrendo juntas. √â a incerteza sobre o par (Clima, Tr√¢nsito). A incerteza conjunta √© sempre maior ou igual √† incerteza de cada vari√°vel individualmente, e √© igual √† soma das incertezas individuais somente se as vari√°veis forem independentes.</p>
                    <p class="mt-2 text-slate-600 font-mono text-sm bg-slate-100 p-2 rounded">$H(X,Y) \le H(X) + H(Y)$</p>
                </div>
                 <div class="p-6 bg-white rounded-xl shadow-md border border-slate-200">
                    <h3 class="font-bold text-lg text-slate-700">Entropia Condicional H(Y|X)</h3>
                    <p class="mt-2 text-slate-600">Mede a incerteza que resta sobre Y, *dado que* j√° conhecemos o valor de X. Qual a incerteza sobre o Tr√¢nsito, sabendo que est√° chovendo? Conhecimento nunca aumenta a incerteza, ent√£o $H(Y|X) \le H(Y)$.</p>
                </div>
            </div>
             <div class="mt-6 p-6 bg-white rounded-xl shadow-md border border-slate-200">
                <h3 class="font-bold text-lg text-slate-700">A Regra da Cadeia</h3>
                <p class="mt-2 text-slate-600">Esses conceitos s√£o ligados pela Regra da Cadeia, que decomp√µe a incerteza total:</p>
                <p class="mt-2 text-slate-800 font-mono text-center text-lg bg-slate-100 p-4 rounded-lg">$H(X,Y) = H(X) + H(Y|X)$</p>
                <p class="mt-2 text-slate-600">A incerteza total sobre (Clima, Tr√¢nsito) √© a incerteza sobre o Clima, mais a incerteza que resta sobre o Tr√¢nsito depois que sabemos como est√° o clima.</p>
            </div>
        </section>

        <section id="mutual" class="content-section">
            <h2 class="text-3xl font-bold text-slate-800">Informa√ß√£o M√∫tua I(X;Y)</h2>
            <p class="mt-4 text-lg text-slate-600 leading-relaxed">
               A **Informa√ß√£o M√∫tua** $I(X;Y)$ mede a informa√ß√£o que X e Y compartilham. Ela quantifica o quanto saber sobre uma vari√°vel reduz a incerteza sobre a outra. √â a medida da depend√™ncia estat√≠stica entre elas.
            </p>
            <div class="mt-8 p-6 bg-white rounded-xl shadow-md border border-slate-200">
                <h3 class="font-bold text-lg text-slate-700">Diagrama de Venn da Entropia</h3>
                <p class="text-slate-600 mb-4">Selecione um cen√°rio para ver como a rela√ß√£o entre duas vari√°veis (X e Y) afeta as entropias. A intersec√ß√£o √© a Informa√ß√£o M√∫tua.</p>
                <select id="venn-scenario-select" class="w-full p-2 border rounded-lg bg-white">
                    <option value="partial">Depend√™ncia Parcial (ex: Chuva e Uso de Guarda-chuva)</option>
                    <option value="independent">Independ√™ncia (ex: Nevar em Curitiba e Sol em T√≥quio)</option>
                    <option value="dependent">Depend√™ncia Total (ex: Y = 2X)</option>
                </select>

                <div class="venn-diagram">
                    <div id="venn-x" class="venn-circle bg-blue-500"></div>
                    <div id="venn-y" class="venn-circle bg-orange-500"></div>
                    <div id="venn-label-hx" class="venn-label">H(X)</div>
                    <div id="venn-label-hy" class="venn-label">H(Y)</div>
                    <div id="venn-label-ixy" class="venn-label">I(X;Y)</div>
                    <div id="venn-label-hxy" class="venn-label">H(X|Y)</div>
                    <div id="venn-label-hyx" class="venn-label">H(Y|X)</div>
                </div>
                 <div id="venn-explanation" class="text-center text-slate-600 leading-relaxed p-4 bg-slate-50 rounded-lg"></div>
            </div>
             <div class="mt-6 p-6 bg-white rounded-xl shadow-md border border-slate-200">
                <h3 class="font-bold text-lg text-slate-700">Aplica√ß√µes da Informa√ß√£o M√∫tua</h3>
                <p class="mt-2 text-slate-600">A Informa√ß√£o M√∫tua √© poderosa por capturar rela√ß√µes n√£o-lineares, sendo usada em:</p>
                <ul class="list-disc list-inside mt-2 space-y-1 text-slate-600">
                    <li><b>Aprendizado de M√°quina:</b> Para selecionar as caracter√≠sticas (features) mais informativas de um dataset para treinar um modelo preditivo.</li>
                    <li><b>Diagn√≥stico M√©dico:</b> Para quantificar a for√ßa da associa√ß√£o entre sintomas e doen√ßas, ajudando a priorizar testes e identificar redund√¢ncias.</li>
                    <li><b>Neuroci√™ncia:</b> Para estudar a conectividade funcional no c√©rebro, medindo a depend√™ncia entre a atividade de diferentes regi√µes.</li>
                </ul>
            </div>
        </section>

        <section id="kl" class="content-section">
            <h2 class="text-3xl font-bold text-slate-800">Entropia Cruzada & Diverg√™ncia KL</h2>
            <p class="mt-4 text-lg text-slate-600 leading-relaxed">
                Em aprendizado de m√°quina, criamos um modelo (Q) para aproximar a realidade (P). A **Diverg√™ncia de Kullback-Leibler** $D_{KL}(P||Q)$ mede a "penalidade em bits" por usar o modelo Q em vez da distribui√ß√£o real P. A **Entropia Cruzada** $H(P,Q)$ √© o custo total de usar o modelo Q.
            </p>
             <div class="info-box">
                <p class="info-box-title">Rela√ß√£o Fundamental e Fun√ß√£o de Perda</p>
                <p class="mt-2 text-slate-600">A rela√ß√£o √© $H(P,Q) = H(P) + D_{KL}(P||Q)$. Como a entropia da realidade $H(P)$ √© fixa, minimizar a Entropia Cruzada durante o treinamento de um modelo √© o mesmo que minimizar a Diverg√™ncia KL. Por isso, a Entropia Cruzada √© uma das fun√ß√µes de perda (loss functions) mais importantes em problemas de classifica√ß√£o.</p>
            </div>
             <div class="mt-6 p-6 bg-white rounded-xl shadow-md border border-slate-200">
                 <h3 class="font-bold text-lg text-slate-700">Laborat√≥rio de Diverg√™ncia KL</h3>
                 <p class="text-slate-600 mb-4">A distribui√ß√£o 'P' √© a realidade (fixa). Ajuste as probabilidades do seu 'Modelo Q' e tente aproxim√°-lo de P. Veja como a Entropia Cruzada e a Diverg√™ncia KL diminuem √† medida que seu modelo melhora.</p>
                 <div class="flex flex-col md:flex-row gap-8 items-start">
                    <div class="w-full md:w-1/2">
                        <div id="kl-controls"></div>
                    </div>
                    <div class="w-full md:w-1/2">
                        <div class="grid grid-cols-3 gap-2 text-center">
                            <div><p class="text-slate-600 text-sm">H(P)</p><p id="kl-hp" class="font-bold text-lg text-blue-600">0</p></div>
                            <div><p class="text-slate-600 text-sm">H(P,Q)</p><p id="kl-hpq" class="font-bold text-lg text-slate-800">0</p></div>
                            <div><p class="text-slate-600 text-sm">$D_{KL}(P||Q)$</p><p id="kl-dkl" class="font-bold text-lg text-orange-500">0</p></div>
                        </div>
                        <div class="chart-container mt-4">
                            <canvas id="klChart"></canvas>
                        </div>
                    </div>
                </div>
            </div>
        </section>

    </main>

<script>
document.addEventListener('DOMContentLoaded', () => {

    const sections = document.querySelectorAll('.content-section');
    const navLinks = document.querySelectorAll('.nav-link');

    function updateActiveState(hash) {
        let activeHash = hash || window.location.hash || '#intro';
        if (!document.querySelector(activeHash)) {
            activeHash = '#intro';
        }

        sections.forEach(section => {
            section.classList.toggle('active', '#' + section.id === activeHash);
        });

        navLinks.forEach(link => {
            link.classList.toggle('active', link.getAttribute('href') === activeHash);
        });
    }

    navLinks.forEach(link => {
        link.addEventListener('click', (e) => {
            e.preventDefault();
            const targetId = link.getAttribute('href');
            history.pushState(null, null, targetId);
            updateActiveState(targetId);
        });
    });

    window.addEventListener('popstate', () => updateActiveState(window.location.hash));

    const log2 = (n) => n > 0 ? Math.log2(n) : 0;

    function calculateEntropy(probs) {
        return -probs.reduce((sum, p) => sum + p * log2(p), 0);
    }
    
    function normalizeProbs(probs, changedIndex, newValue) {
        let newProbs = [...probs];
        newProbs[changedIndex] = newValue;
        
        let sum = newProbs.reduce((a, b) => a + b, 0);
        let otherSum = sum - newValue;
        
        if (otherSum > 1 - newValue) {
            let scale = (1 - newValue) / otherSum;
            for (let i = 0; i < newProbs.length; i++) {
                if (i !== changedIndex) {
                    newProbs[i] *= scale;
                }
            }
        }
        
        sum = newProbs.reduce((a, b) => a + b, 0);
        if (Math.abs(1 - sum) > 1e-9) {
           const scale = 1 / sum;
           newProbs = newProbs.map(p => p * scale);
        }
        
        return newProbs;
    }


    const coin = document.getElementById('coin');
    const bitInfo = document.getElementById('bit-info');
    const flipCoinBtn = document.getElementById('flip-coin-btn');
    if(flipCoinBtn) {
        flipCoinBtn.addEventListener('click', () => {
            const result = Math.random() < 0.5 ? 'C' : 'K';
            coin.textContent = result === 'C' ? 'üôÇ' : 'üëë';
            bitInfo.textContent = '1 bit';
            setTimeout(() => {
                 coin.textContent = '?';
                 bitInfo.textContent = '0 bits';
            }, 2000);
        });
    }

    let entropyChart, klChart;

    function setupEntropyLab() {
        const diceControlsContainer = document.getElementById('dice-controls');
        if (!diceControlsContainer) return;
        diceControlsContainer.innerHTML = '';
        
        const entropyValue = document.getElementById('entropy-value');
        const diceLabels = ['1', '2', '3', '4', '5', '6'];
        let diceProbs = Array(6).fill(1 / 6);
        
        const update = () => {
            const entropy = calculateEntropy(diceProbs);
            entropyValue.textContent = `${entropy.toFixed(3)} bits`;
            if (entropyChart) {
                entropyChart.data.datasets[0].data = diceProbs;
                entropyChart.update('none');
            }
            document.querySelectorAll('#dice-controls .slider-label').forEach((label, i) => {
                label.textContent = `${(diceProbs[i] * 100).toFixed(1)}%`;
            });
            document.querySelectorAll('#dice-controls input[type="range"]').forEach((input, i) => {
                input.value = diceProbs[i];
            });
        };

        diceLabels.forEach((label, i) => {
            const controlDiv = document.createElement('div');
            controlDiv.className = 'mb-2';
            controlDiv.innerHTML = `
                <label class="text-sm font-medium text-slate-700 flex justify-between">
                    <span>Face ${label}:</span>
                    <span class="font-mono bg-slate-100 p-1 rounded slider-label">${(diceProbs[i] * 100).toFixed(1)}%</span>
                </label>
                <input type="range" min="0" max="1" step="0.01" value="${diceProbs[i]}" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer">
            `;
            diceControlsContainer.appendChild(controlDiv);

            controlDiv.querySelector('input').addEventListener('input', (e) => {
                diceProbs = normalizeProbs(diceProbs, i, parseFloat(e.target.value));
                update();
            });
        });

        const ctx = document.getElementById('entropyChart').getContext('2d');
        if(window.entropyChart instanceof Chart) window.entropyChart.destroy();
        entropyChart = new Chart(ctx, {
            type: 'bar',
            data: { labels: diceLabels, datasets: [{ label: 'Probabilidade', data: diceProbs, backgroundColor: 'rgba(59, 130, 246, 0.5)', borderColor: 'rgba(59, 130, 246, 1)', borderWidth: 1 }] },
            options: { responsive: true, maintainAspectRatio: false, scales: { y: { beginAtZero: true, max: 1, title: { display: true, text: 'Probabilidade' } } }, plugins: { legend: { display: false }, tooltip: { enabled: true } } }
        });
        window.entropyChart = entropyChart;
        update();
    }
    
    let huffmanState;

    function setupHuffmanLab() {
        const huffmanVis = document.getElementById('huffman-visualization');
        const huffmanStepBtn = document.getElementById('huffman-step-btn');
        const huffmanResetBtn = document.getElementById('huffman-reset-btn');
        const huffmanResults = document.getElementById('huffman-results');
        const huffmanTableBody = document.getElementById('huffman-table-body');
        const huffmanSummary = document.getElementById('huffman-summary');
        
        if(!huffmanVis) return;

        const resetHuffman = () => {
            const text = "A_DEAD_DAD_CEDED_A_BEAD";
            const freqs = {};
            for (const char of text) { freqs[char] = (freqs[char] || 0) + 1; }

            huffmanState = {
                step: 0,
                nodes: Object.entries(freqs).map(([char, freq]) => ({ char, freq, children: [] })).sort((a,b) => a.freq - b.freq || a.char.localeCompare(b.char)),
                text: text,
                finalCodes: null,
                entropy: calculateEntropy(Object.values(freqs).map(f => f / text.length))
            };
            huffmanVis.innerHTML = '<p id="huffman-status" class="text-center text-slate-500">Pronto. Clique em "Pr√≥ximo Passo".</p>';
            huffmanResults.classList.add('hidden');
            huffmanTableBody.innerHTML = '';
            huffmanSummary.innerHTML = '';
            huffmanStepBtn.disabled = false;
        };
        
        const huffmanStep = () => {
            if (huffmanState.nodes.length > 1) {
                huffmanState.step++;
                const node1 = huffmanState.nodes.shift();
                const node2 = huffmanState.nodes.shift();
                const newNode = { char: `(N${huffmanState.step})`, freq: node1.freq + node2.freq, children: [node1, node2] };
                huffmanState.nodes.push(newNode);
                huffmanState.nodes.sort((a,b) => a.freq - b.freq || a.char.localeCompare(b.char));

                huffmanVis.innerHTML = `
                    <p class="font-semibold mb-2">Passo ${huffmanState.step}: Combinando os 2 n√≥s de menor frequ√™ncia</p>
                    <div class="flex justify-around items-center text-center">
                        <div class="p-2 border rounded bg-blue-100">"${node1.char}"<br>Freq: ${node1.freq}</div> <div class="text-2xl">+</div>
                        <div class="p-2 border rounded bg-blue-100">"${node2.char}"<br>Freq: ${node2.freq}</div> <div class="text-2xl">‚Üí</div>
                        <div class="p-2 border rounded bg-green-100">"${newNode.char}"<br>Freq: ${newNode.freq}</div>
                    </div>
                    <p class="font-semibold mt-4">Fila de Prioridade Atual:</p>
                    <div class="flex flex-wrap gap-2 mt-2">${huffmanState.nodes.map(n => `<div class="p-2 border rounded bg-slate-100 text-sm">"${n.char}": ${n.freq}</div>`).join('')}</div>
                `;
            } else {
                huffmanVis.innerHTML = '<p class="font-semibold text-center text-green-600">√Årvore Completa!</p>';
                huffmanStepBtn.disabled = true;
                generateHuffmanCodes();
            }
        };

        const generateHuffmanCodes = () => {
            const codes = {};
            function traverse(node, code) {
                if (!node) return;
                if (node.children.length === 0) { codes[node.char] = code || '0'; return; }
                traverse(node.children[0], code + '0');
                traverse(node.children[1], code + '1');
            }
            traverse(huffmanState.nodes[0], '');
            huffmanState.finalCodes = codes;
            displayHuffmanResults();
        };
    
        const displayHuffmanResults = () => {
            huffmanResults.classList.remove('hidden');
            let totalHuffmanBits = 0;
            const originalFreqs = {};
            for (const char of huffmanState.text) { originalFreqs[char] = (originalFreqs[char] || 0) + 1; }

            const sortedChars = Object.keys(huffmanState.finalCodes).sort();
            
            huffmanTableBody.innerHTML = '';
            for (const char of sortedChars) {
                const code = huffmanState.finalCodes[char];
                const freq = originalFreqs[char];
                if (!freq) continue;
                totalHuffmanBits += freq * code.length;
                const row = document.createElement('tr');
                row.innerHTML = `
                    <td class="px-6 py-4 whitespace-nowrap"><div class="text-sm font-medium text-gray-900">${char === '_' ? 'ESPA√áO' : char}</div></td>
                    <td class="px-6 py-4 whitespace-nowrap"><div class="text-sm text-gray-500">${freq}</div></td>
                    <td class="px-6 py-4 whitespace-nowrap"><div class="text-sm text-gray-500 font-mono">${code}</div></td>
                    <td class="px-6 py-4 whitespace-nowrap"><div class="text-sm text-gray-500">${code.length}</div></td>
                `;
                huffmanTableBody.appendChild(row);
            }

            const avgHuffmanLength = totalHuffmanBits / huffmanState.text.length;
            const uniqueChars = Object.keys(originalFreqs).length;
            const fixedLength = Math.ceil(log2(uniqueChars));
            const totalFixedBits = fixedLength * huffmanState.text.length;

            huffmanSummary.innerHTML = `
                <p>Comprimento m√©dio (Huffman): ${avgHuffmanLength.toFixed(3)} bits/s√≠mbolo</p>
                <p>Comprimento fixo necess√°rio: ${fixedLength} bits/s√≠mbolo</p>
                <p>Entropia da fonte (limite te√≥rico): ${huffmanState.entropy.toFixed(3)} bits/s√≠mbolo</p>
                <p class="mt-2 text-green-700">Total de bits (Huffman): ${totalHuffmanBits} | Total de bits (Fixo): ${totalFixedBits}</p>
            `;
        };

        huffmanResetBtn.addEventListener('click', resetHuffman);
        huffmanStepBtn.addEventListener('click', huffmanStep);
        resetHuffman();
    }

    function setupVennDiagram() {
        const vennScenarioSelect = document.getElementById('venn-scenario-select');
        if (!vennScenarioSelect) return;
        const vennX = document.getElementById('venn-x');
        const vennY = document.getElementById('venn-y');
        const vennLabelHx = document.getElementById('venn-label-hx');
        const vennLabelHy = document.getElementById('venn-label-hy');
        const vennLabelIxy = document.getElementById('venn-label-ixy');
        const vennLabelHxy = document.getElementById('venn-label-hxy');
        const vennLabelHyx = document.getElementById('venn-label-hyx');
        const vennExplanation = document.getElementById('venn-explanation');
        
        const vennScenarios = {
            partial: {
                x: { left: '10%', width: '60%', height: '100%' }, y: { left: '30%', width: '60%', height: '100%' },
                labels: { hx: { top: '45%', left: '20%' }, hy: { top: '45%', right: '20%' }, ixy: { top: '45%', left: '46%' }, hxy: { top: '10%', left: '15%' }, hyx: { top: '10%', right: '15%' } },
                explanation: `<b>Depend√™ncia Parcial:</b> H(X) e H(Y) se sobrep√µem. A intersec√ß√£o √© a Informa√ß√£o M√∫tua $I(X;Y) > 0$. Conhecer X reduz a incerteza sobre Y, mas n√£o a elimina, ent√£o a entropia condicional $H(Y|X) > 0$.`
            },
            independent: {
                x: { left: '0%', width: '48%', height: '100%' }, y: { left: '52%', width: '48%', height: '100%' },
                labels: { hx: { top: '45%', left: '24%' }, hy: { top: '45%', right: '24%' }, ixy: { top: '45%', left: '48%', display: 'none' }, hxy: { top: '10%', left: '20%' }, hyx: { top: '10%', right: '20%' } },
                explanation: `<b>Independ√™ncia:</b> N√£o h√° sobreposi√ß√£o. A Informa√ß√£o M√∫tua $I(X;Y) = 0$. Conhecer X n√£o informa nada sobre Y, ent√£o $H(Y|X) = H(Y)$. A entropia conjunta √© a soma das entropias individuais: $H(X,Y) = H(X) + H(Y)$.`
            },
            dependent: {
                x: { left: '20%', width: '60%', height: '100%' }, y: { left: '20%', width: '60%', height: '100%' },
                 labels: { hx: { display: 'none' }, hy: { display: 'none' }, ixy: { top: '45%', left: '46%' }, hxy: { display: 'none' }, hyx: { display: 'none' } },
                explanation: `<b>Depend√™ncia Total:</b> Os c√≠rculos se sobrep√µem perfeitamente. A Informa√ß√£o M√∫tua √© igual √† entropia individual: $I(X;Y) = H(X) = H(Y)$. Conhecer X elimina toda a incerteza sobre Y, ent√£o a entropia condicional $H(Y|X) = 0$.`
            }
        };

        const updateVennDiagram = (scenario) => {
            const s = vennScenarios[scenario];
            Object.assign(vennX.style, s.x);
            Object.assign(vennY.style, s.y);
            
            const allLabels = { hx: vennLabelHx, hy: vennLabelHy, ixy: vennLabelIxy, hxy: vennLabelHxy, hyx: vennLabelHyx };
            Object.values(allLabels).forEach(l => l.style.display = 'block');
            
            Object.keys(s.labels).forEach(key => Object.assign(allLabels[key].style, s.labels[key]));
            vennExplanation.innerHTML = s.explanation;
        }
        vennScenarioSelect.addEventListener('change', (e) => updateVennDiagram(e.target.value));
        updateVennDiagram('partial');
    }

    function setupKLLab() {
        const klControlsContainer = document.getElementById('kl-controls');
        if(!klControlsContainer) return;
        klControlsContainer.innerHTML = '';
        
        const klHp = document.getElementById('kl-hp');
        const klHpq = document.getElementById('kl-hpq');
        const klDkl = document.getElementById('kl-dkl');
        
        const klLabels = ['A', 'B', 'C', 'D'];
        const distP = [0.1, 0.2, 0.6, 0.1];
        let distQ = [0.25, 0.25, 0.25, 0.25];

        const calculateKL = () => {
            const H_P = calculateEntropy(distP);
            const H_PQ = -distP.reduce((sum, p, i) => sum + p * log2(distQ[i]), 0);
            const D_KL = H_PQ - H_P;
            
            klHp.textContent = H_P.toFixed(3);
            klHpq.textContent = H_PQ.toFixed(3);
            klDkl.textContent = D_KL.toFixed(3);
            
            if(klChart) {
                klChart.data.datasets[1].data = distQ;
                klChart.update('none');
            }

             document.querySelectorAll('#kl-controls .slider-label').forEach((label, i) => {
                label.textContent = `${(distQ[i] * 100).toFixed(1)}%`;
            });
            document.querySelectorAll('#kl-controls input[type="range"]').forEach((input, i) => {
                input.value = distQ[i];
            });
        }

        klLabels.forEach((label, i) => {
            const controlDiv = document.createElement('div');
            controlDiv.className = 'mb-2';
            controlDiv.innerHTML = `
                <label class="text-sm font-medium text-slate-700 flex justify-between">
                    <span>Modelo Q(${label}):</span>
                    <span class="font-mono bg-slate-100 p-1 rounded slider-label">${(distQ[i] * 100).toFixed(1)}%</span>
                </label>
                <input type="range" min="0.01" max="1" step="0.01" value="${distQ[i]}" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer">
            `;
            klControlsContainer.appendChild(controlDiv);

            controlDiv.querySelector('input').addEventListener('input', (e) => {
                distQ = normalizeProbs(distQ, i, parseFloat(e.target.value));
                calculateKL();
            });
        });

        const ctx = document.getElementById('klChart').getContext('2d');
        if(window.klChart instanceof Chart) window.klChart.destroy();
        klChart = new Chart(ctx, {
            type: 'bar',
            data: { labels: klLabels, datasets: [ { label: 'Realidade P', data: distP, backgroundColor: 'rgba(59, 130, 246, 0.5)', borderColor: 'rgba(59, 130, 246, 1)', borderWidth: 1 }, { label: 'Modelo Q', data: distQ, backgroundColor: 'rgba(249, 115, 22, 0.5)', borderColor: 'rgba(249, 115, 22, 1)', borderWidth: 1 } ] },
            options: { responsive: true, maintainAspectRatio: false, scales: { y: { beginAtZero: true, max: 1 } }, plugins: { legend: { position: 'top' } } }
        });
        window.klChart = klChart;
        calculateKL();
    }
    
    // Initial setup
    updateActiveState();
    setupEntropyLab();
    setupHuffmanLab();
    setupVennDiagram();
    setupKLLab();

});
</script>
</body>
</html>
